# Intent_Recognition_with_BERT-TPU
Intent Recognition with Bert Model In Google Colab TPU using Tensorflow

BERT(Bidirectional Encoder Representations from Transformers) is pretrained model for Natural Language Processing(NLP) tasks. It is introduced by Google AI team in October 2018.It is trained on Wikipedia and Corpus dataset, it knows the language and context which is quiet decent. It has two versions Base(12 encoders) and Large (24 encoders). BERT is built on top of he multiple clever ideas by the NLP community. Some examples are ELMo, the OpenAI Transformer and The Transformer.

If you want to get more information then follow the following links.
- [See BERT on Paper](https://arxiv.org/pdf/1810.04805.pdf)
- [See BERT on GitHub](https://github.com/google-research/bert)
- [See BERT on TensorHub](https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1)
